{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vjpLZ80fWZx"
   },
   "source": [
    "1-Sep-2019 to 12-Jul-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGv-UksLfWZz"
   },
   "outputs": [],
   "source": [
    "#Import relevant modules\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mon</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>09</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>09</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>09</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>09</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2015</td>\n",
       "      <td>06</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year mon day\n",
       "0   2014  09  14\n",
       "1   2014  09  17\n",
       "2   2014  09  21\n",
       "3   2014  09  24\n",
       "4   2014  09  27\n",
       "..   ...  ..  ..\n",
       "78  2015  06  27\n",
       "79  2015  07  01\n",
       "80  2015  07  05\n",
       "81  2015  07  08\n",
       "82  2015  07  12\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get whole season schedule\n",
    "df_sch=pd.read_csv('../data/raw/schedule_s1415.csv', dtype={'year':str,'mon':str,'day':str})\n",
    "df_sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=14\n",
    "URL_date_suffix=df_sch.iloc[index].year+'/'+df_sch.iloc[index].mon+'/'+df_sch.iloc[index].day\n",
    "URL_race_no_suffix='1'\n",
    "URL_racing_res = 'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate='+URL_date_suffix+'&RaceNo='+URL_race_no_suffix\n",
    "internation_race_day =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate=2014/11/02&RaceNo=1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_racing_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL_racing_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mon</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year mon day\n",
       "10  2014  10  19\n",
       "11  2014  10  22\n",
       "12  2014  10  26\n",
       "13  2014  10  29\n",
       "14  2014  11  02\n",
       "15  2014  11  09\n",
       "16  2014  11  12\n",
       "17  2014  11  15\n",
       "18  2014  11  19\n",
       "19  2014  11  23\n",
       "20  2014  11  26\n",
       "21  2014  11  30\n",
       "22  2014  12  03\n",
       "23  2014  12  07\n",
       "24  2014  12  10\n",
       "25  2014  12  14\n",
       "26  2014  12  17\n",
       "27  2014  12  20\n",
       "28  2014  12  28\n",
       "29  2015  01  01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sch[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please change the path to the location of your chromedriver\n",
    "driver = webdriver.Chrome('/Users/Hei/Applications/chromedriver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pref_df():\n",
    "    '''Create DataFrame from performance table data'''\n",
    "    \n",
    "    global soup\n",
    "    #Get #Get all <td> elements in html\n",
    "    list_performance = get_html_from_soup(soup)\n",
    "\n",
    "    #Number of columns of performance data table\n",
    "    num_of_columns=12\n",
    "    #Number of cells in performance data table\n",
    "    num_of_table_element=len(list_performance)\n",
    "    #Number of horse\n",
    "    num_of_horse = int(num_of_table_element/num_of_columns)\n",
    "    \n",
    "    #Create dictionary for storing perfotmance table data\n",
    "    list_columns = ['place','horse_no','horse','jockey','trainer','actual_weight',\\\n",
    "                 'declared_horse_weight','draw','lbw','running_position','finish_time',\\\n",
    "                 'win_odds']\n",
    "\n",
    "    #Load performance table data into dataframe\n",
    "    table = soup.find_all(class_=\"performance\")\n",
    "    table_data = [i.find_all('td') for i in table]\n",
    "    l = [i.text.strip() for i in table_data[0]]\n",
    "    table=[]\n",
    "    for i in range(1,int(len(l)/12)):\n",
    "        table.append(l[12*i:12*i+12])\n",
    "    df_table=pd.DataFrame(table,columns=list_columns)\n",
    "  \n",
    "    return df_table,num_of_horse\n",
    "\n",
    "def get_html_from_soup(soup):\n",
    "    #Get all <td> elements in html\n",
    "    data_performance=soup.find_all(class_=\"f_fs12\")[1:-2][0]\n",
    "    list_performance=data_performance.find_all('td')\n",
    "    return list_performance\n",
    "\n",
    "def create_race_info_df():\n",
    "    global soup,num_of_horse,URL_date_suffix\n",
    "    \n",
    "    table = soup.find_all(class_=\"race_tab\")\n",
    "    table_data = [i.find_all('td')for i in table]\n",
    "    l = \"\".join([i.text for i in table_data[0]])\n",
    "    \n",
    "    line = soup.find_all(class_=\"f_fl f_fs13\")\n",
    "    line = line[0].text\n",
    "    location=re.search(r'\\w+\\s{2,}(.+)$',line).group(1)\n",
    "    \n",
    "\n",
    "    d=[[re.findall(\"RACE\\s(\\d+)\", l)[0]+re.findall(r\"RACE.+(\\(\\d+\\))\", l)[0],re.search(r'\\)(.+)Going',l).group(1),\n",
    "      re.findall(\"Going \\:(FIRM|GOOD TO FIRM|GOOD|GOOD TO YIELDING|YIELDING|YIELDING TO SOFT|SOFT|HEAVY|GOOD TO SOFT|WET FAST|FAST|SLOW|WET SLOW|RAIN AFFECTED|NORMAL WATERING)\\w+\", l)[0],\n",
    "       re.findall(\"Course \\:(.+)HK\", l)[0],\n",
    "       re.findall(\"HK\\$ \\d+\\,\\d*\\,*\\d*\",l)[0],location,URL_date_suffix] for i in range(num_of_horse)]\n",
    "\n",
    "    df=pd.DataFrame(d)\n",
    "    df.columns=('race','class','going','turf','prize','location','date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_data_df(performance,race_info):\n",
    "    '''Create a DataFrame containing performance and race info data'''\n",
    "    df_data=pd.concat([performance,race_info],axis=1)\n",
    "    return df_data\n",
    "\n",
    "def get_num_of_race():\n",
    "    '''Find out the number of image for each race'''\n",
    "    pattern_img = re.compile('.+src=\"/racing/info/StaticFile/Images/Racing/racecard_rt.+')\n",
    "    img_list = [ str(tag) for tag in soup.find_all('img') if pattern_img.match(str(tag)) ]\n",
    "    race_no = [int(re.search(r'Racing/racecard_rt_(\\d+)',str(img)).group(1)) for img in img_list]\n",
    "\n",
    "    return max(race_no)\n",
    "\n",
    "def get_next_race():\n",
    "    '''Update URL_date_suffix, URL_race_no_suffix and return the url of next race. If it is internation event, skip current day'''\n",
    "    global soup,URL_date_suffix,URL_race_no_suffix,index\n",
    "\n",
    "    #local event:\n",
    "    #get next race no. suffix in url\n",
    "    max_race = get_num_of_race()\n",
    "    if (int(URL_race_no_suffix)+1<=max_race):\n",
    "        URL_race_no_suffix = str(int(URL_race_no_suffix)+1)\n",
    "    else:\n",
    "        #get next date suffix in url\n",
    "        index+=1\n",
    "        URL_date_suffix=df_sch.iloc[index].year+'/'+df_sch.iloc[index].mon+'/'+df_sch.iloc[index].day\n",
    "        URL_race_no_suffix = str(1)\n",
    "    \n",
    "    next_race_url='https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate='+URL_date_suffix+'&RaceNo='+URL_race_no_suffix\n",
    "    return next_race_url\n",
    "\n",
    "def check_race():\n",
    "    '''Check whether the race is cancelled. Return True if the race is scheduled and False if the race is cancalled'''\n",
    "    perf_content = soup.find(class_=\"race_tab\")\n",
    "    return bool(perf_content)\n",
    "\n",
    "def isIntRace():\n",
    "    '''Return True if it is an international event. Otherwise return false.'''\n",
    "    global internation_race_day\n",
    "    return True if URL_date_suffix in internation_race_day else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create an empty dataframe storing all data from the whole season\n",
    "df_output = pd.DataFrame(columns=['place','horse_no','horse','jockey','trainer','actual_weight',\\\n",
    "                 'declared_horse_weight','draw','lbw','running_position','finish_time',\\\n",
    "                 'win_odds','race','class','going','turf','prize','location','date'])\n",
    "while True:\n",
    "    #Scrape data using chromedriver\n",
    "    #If the code fail to fetch enough html, please extend the sleep time\n",
    "    driver.get(URL_racing_res)\n",
    "    time.sleep(6)\n",
    "    subhtml = driver.page_source\n",
    "    soup = BeautifulSoup(subhtml, 'html.parser')\n",
    "    \n",
    "    if isIntRace():\n",
    "        #Skip current page and go to next day\n",
    "        URL_racing_res=get_next_race()\n",
    "    else:\n",
    "        #Get html data only if the race is scheduled. Otherwise, skip the page.\n",
    "        if check_race():\n",
    "            #Create dataframe containing performance data\n",
    "            df_perf,num_of_horse = create_pref_df()\n",
    "            #Creat dataframe containing racing info\n",
    "            df_race_info=create_race_info_df()\n",
    "            #Creat dataframe for analysis by concatenating df_perf and df_race_info\n",
    "            df_data = create_data_df(df_perf,df_race_info)\n",
    "            #Append df_output with df_data\n",
    "            df_output=pd.concat([df_output,df_data],axis=0)\n",
    "\n",
    "        #Update the url for next race\n",
    "        if index==21 and (URL_race_no_suffix==str(get_num_of_race())):\n",
    "            break\n",
    "        else:\n",
    "            URL_racing_res=get_next_race()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_of_race()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_date_suffix,URL_race_no_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('../data/raw/performance_2014_11.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
