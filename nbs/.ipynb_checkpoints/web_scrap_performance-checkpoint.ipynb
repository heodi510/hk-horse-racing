{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vjpLZ80fWZx"
   },
   "source": [
    "1-Sep-2019 to 12-Jul-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGv-UksLfWZz"
   },
   "outputs": [],
   "source": [
    "#Import relevant modules\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get whole season schedule\n",
    "df_sch=pd.read_csv('../data/schedule/schedule_s1314.csv', dtype={'year':str,'mon':str,'day':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=81\n",
    "URL_date_suffix=df_sch.iloc[index].year+'/'+df_sch.iloc[index].mon+'/'+df_sch.iloc[index].day\n",
    "URL_race_no_suffix='1'\n",
    "URL_racing_res = 'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate='+URL_date_suffix+'&RaceNo='+URL_race_no_suffix\n",
    "internation_race_day =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate=2014/05/04&RaceNo=1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_racing_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL_racing_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mon</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2014</td>\n",
       "      <td>03</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2014</td>\n",
       "      <td>04</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2014</td>\n",
       "      <td>05</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2014</td>\n",
       "      <td>06</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2014</td>\n",
       "      <td>07</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2014</td>\n",
       "      <td>07</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year mon day\n",
       "50  2014  03  12\n",
       "51  2014  03  16\n",
       "52  2014  03  19\n",
       "53  2014  03  23\n",
       "54  2014  03  26\n",
       "55  2014  03  30\n",
       "56  2014  04  02\n",
       "57  2014  04  06\n",
       "58  2014  04  09\n",
       "59  2014  04  13\n",
       "60  2014  04  16\n",
       "61  2014  04  21\n",
       "62  2014  04  27\n",
       "63  2014  04  30\n",
       "64  2014  05  04\n",
       "65  2014  05  07\n",
       "66  2014  05  10\n",
       "67  2014  05  14\n",
       "68  2014  05  17\n",
       "69  2014  05  21\n",
       "70  2014  05  25\n",
       "71  2014  05  28\n",
       "72  2014  06  01\n",
       "73  2014  06  05\n",
       "74  2014  06  08\n",
       "75  2014  06  11\n",
       "76  2014  06  15\n",
       "77  2014  06  18\n",
       "78  2014  06  22\n",
       "79  2014  06  25\n",
       "80  2014  06  28\n",
       "81  2014  07  01\n",
       "82  2014  07  06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sch[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please change the path to the location of your chromedriver\n",
    "driver = webdriver.Chrome('/Users/Hei/Applications/chromedriver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pref_df():\n",
    "    '''Create DataFrame from performance table data'''\n",
    "    \n",
    "    global soup\n",
    "    #Get #Get all <td> elements in html\n",
    "    list_performance = get_html_from_soup(soup)\n",
    "\n",
    "    #Number of columns of performance data table\n",
    "    num_of_columns=12\n",
    "    #Number of cells in performance data table\n",
    "    num_of_table_element=len(list_performance)\n",
    "    #Number of horse\n",
    "    num_of_horse = int(num_of_table_element/num_of_columns)\n",
    "    \n",
    "    #Create dictionary for storing perfotmance table data\n",
    "    list_columns = ['place','horse_no','horse','jockey','trainer','actual_weight',\\\n",
    "                 'declared_horse_weight','draw','lbw','running_position','finish_time',\\\n",
    "                 'win_odds']\n",
    "\n",
    "    #Load performance table data into dataframe\n",
    "    table = soup.find_all(class_=\"performance\")\n",
    "    table_data = [i.find_all('td') for i in table]\n",
    "    l = [i.text.strip() for i in table_data[0]]\n",
    "    table=[]\n",
    "    for i in range(1,int(len(l)/12)):\n",
    "        table.append(l[12*i:12*i+12])\n",
    "    df_table=pd.DataFrame(table,columns=list_columns)\n",
    "  \n",
    "    return df_table,num_of_horse\n",
    "\n",
    "def get_html_from_soup(soup):\n",
    "    #Get all <td> elements in html\n",
    "    data_performance=soup.find_all(class_=\"f_fs12\")[1:-2][0]\n",
    "    list_performance=data_performance.find_all('td')\n",
    "    return list_performance\n",
    "\n",
    "def create_race_info_df():\n",
    "    global soup,num_of_horse,URL_date_suffix\n",
    "    \n",
    "    table = soup.find_all(class_=\"race_tab\")\n",
    "    table_data = [i.find_all('td')for i in table]\n",
    "    l = \"\".join([i.text for i in table_data[0]])\n",
    "    \n",
    "    line = soup.find_all(class_=\"f_fl f_fs13\")\n",
    "    line = line[0].text\n",
    "    location=re.search(r'\\w+\\s{2,}(.+)$',line).group(1)\n",
    "    \n",
    "\n",
    "    d=[[re.findall(\"RACE\\s(\\d+)\", l)[0]+re.findall(r\"RACE.+(\\(\\d+\\))\", l)[0],re.search(r'\\)(.+)Going',l).group(1),\n",
    "      re.findall(\"Going \\:(FIRM|GOOD TO FIRM|GOOD|GOOD TO YIELDING|YIELDING|YIELDING TO SOFT|SOFT|HEAVY|GOOD TO SOFT|WET FAST|FAST|SLOW|WET SLOW|RAIN AFFECTED|NORMAL WATERING)\\w+\", l)[0],\n",
    "       re.findall(\"Course \\:(.+)HK\", l)[0],\n",
    "       re.findall(\"HK\\$ \\d+\\,\\d*\\,*\\d*\",l)[0],location,URL_date_suffix] for i in range(num_of_horse)]\n",
    "\n",
    "    df=pd.DataFrame(d)\n",
    "    df.columns=('race','class','going','turf','prize','location','date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_data_df(performance,race_info):\n",
    "    '''Create a DataFrame containing performance and race info data'''\n",
    "    df_data=pd.concat([performance,race_info],axis=1)\n",
    "    return df_data\n",
    "\n",
    "def get_num_of_race():\n",
    "    '''Find out the number of image for each race'''\n",
    "    pattern_img = re.compile('.+src=\"/racing/info/StaticFile/Images/Racing/racecard_rt.+')\n",
    "    img_list = [ str(tag) for tag in soup.find_all('img') if pattern_img.match(str(tag)) ]\n",
    "    race_no = [int(re.search(r'Racing/racecard_rt_(\\d+)',str(img)).group(1)) for img in img_list]\n",
    "\n",
    "    return max(race_no)\n",
    "\n",
    "def get_next_race():\n",
    "    '''Update URL_date_suffix, URL_race_no_suffix and return the url of next race. If it is internation event, skip current day'''\n",
    "    global soup,URL_date_suffix,URL_race_no_suffix,index\n",
    "\n",
    "    #local event:\n",
    "    #get next race no. suffix in url\n",
    "    max_race = get_num_of_race()\n",
    "    if (int(URL_race_no_suffix)+1<=max_race):\n",
    "        URL_race_no_suffix = str(int(URL_race_no_suffix)+1)\n",
    "    else:\n",
    "        #get next date suffix in url\n",
    "        index+=1\n",
    "        URL_date_suffix=df_sch.iloc[index].year+'/'+df_sch.iloc[index].mon+'/'+df_sch.iloc[index].day\n",
    "        URL_race_no_suffix = str(1)\n",
    "    \n",
    "    next_race_url='https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx?RaceDate='+URL_date_suffix+'&RaceNo='+URL_race_no_suffix\n",
    "    return next_race_url\n",
    "\n",
    "def check_race():\n",
    "    '''Check whether the race is cancelled. Return True if the race is scheduled and False if the race is cancalled'''\n",
    "    perf_content = soup.find(class_=\"race_tab\")\n",
    "    return bool(perf_content)\n",
    "\n",
    "def isIntRace():\n",
    "    '''Return True if it is an international event. Otherwise return false.'''\n",
    "    global internation_race_day\n",
    "    return True if URL_date_suffix in internation_race_day else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create an empty dataframe storing all data from the whole season\n",
    "df_output = pd.DataFrame(columns=['place','horse_no','horse','jockey','trainer','actual_weight',\\\n",
    "                 'declared_horse_weight','draw','lbw','running_position','finish_time',\\\n",
    "                 'win_odds','race','class','going','turf','prize','location','date'])\n",
    "while True:\n",
    "    #Scrape data using chromedriver\n",
    "    #If the code fail to fetch enough html, please extend the sleep time\n",
    "    driver.get(URL_racing_res)\n",
    "    time.sleep(6)\n",
    "    subhtml = driver.page_source\n",
    "    soup = BeautifulSoup(subhtml, 'html.parser')\n",
    "    \n",
    "    if isIntRace():\n",
    "        #Skip current page and go to next day\n",
    "        URL_racing_res=get_next_race()\n",
    "    else:\n",
    "        #Get html data only if the race is scheduled. Otherwise, skip the page.\n",
    "        if check_race():\n",
    "            #Create dataframe containing performance data\n",
    "            df_perf,num_of_horse = create_pref_df()\n",
    "            #Creat dataframe containing racing info\n",
    "            df_race_info=create_race_info_df()\n",
    "            #Creat dataframe for analysis by concatenating df_perf and df_race_info\n",
    "            df_data = create_data_df(df_perf,df_race_info)\n",
    "            #Append df_output with df_data\n",
    "            df_output=pd.concat([df_output,df_data],axis=0)\n",
    "\n",
    "        #Update the url for next race\n",
    "        if index==82 and (URL_race_no_suffix==str(get_num_of_race())):\n",
    "            break\n",
    "        else:\n",
    "            URL_racing_res=get_next_race()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_of_race()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_date_suffix,URL_race_no_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('../data/raw/performance_2014_07.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
